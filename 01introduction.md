# 绪论

## 什么是机器学习？

人可以通过经验学习，比方说“朝霞不出门，晚霞行千里”，就是通过经验得来的知识。获得知识后，即使在不同的地点，不同的时间，看到不同的霞，我们也能作出正确的判断。那么，机器是否也能学习并利用经验，从而对一些未出现过的情况，在不通过显式编程（人作出判断并告诉机器）的情况下也能作出正确的预测呢？答案是可以的，这就是**机器学习**。

对于机器来说，**经验**是通过**数据**传达的。机器学习的主要研究内容就是从数据中产生**模型**的算法，也即**学习算法**。Mitchell给出一个更为形式化的定义，假设我们用P来表示程序处理任务T时的性能，如果程序通过利用经验E提高了在任务T上的性能，则称该程序对E进行了学习。

在本书中，**模型**泛指所有从数据中学得的结果，在别的文献中，也有对**模型**和**模式**作出区分的，模型指学得的全局性结果（比如一棵决策树），模式指学得的局部性结果（比如一条规则）。

## 基本概念

要进行机器学习，首先要有数据，我们可以收集一组结构相同的记录，这组记录的集合就称为**数据集**。比如下面这个西瓜数据集：

|编号|色泽|根蒂|敲声|
|:-:|:-:|:-:|:-:|
|001|青绿|蜷缩|浊响|
|002|乌黑|稍蜷|沉闷|
|003|浅白|硬挺|清脆|

**注**：实际使用数据时往往需要先进行编码，即把文本改为数值（比如青绿=1，乌黑=2，等等），以便计算机进行处理。

接下来给出一些基本概念的定义：

#### 示例(instance)，样本(sample)<br>
> 数据集中的每条记录是对一个事件或对象（比如这里的西瓜）的描述，也称作示例或者样本。特别地，有时会把整个数据集称为一个样本，因为数据集可以看作是从样本空间中抽样所得。这时候就需要根据上下文信息来进行判断了。

#### 属性(attribute)，特征(feature)，属性值(attribute value)<br>
> 对象具备一些性质，并由此可以进行区分，这些性质就称为属性或者特征，比方说表格中的色泽、根蒂和敲声。不同对象在这些属性上会有不同的取值，这个取值就称为属性值。

#### 属性空间(attribute space)，样本空间(sample space)，输入空间，特征向量(feature vector)<br>
> 由属性张成的空间，比方说上面的表格中有3个属性，那就可以张成一个3维空间，每个样本都可以用空间中的一个点来表示，这个点对应于一个坐标向量，所以有时也把一个样本称为一个特征向量。

#### 维数(dimensionality)<br>
> 即数据集中每个样本拥有的特征数目。

#### 学习(learning)，训练(training)，训练样本(training sample)，训练示例(training instance)<br>
> 从数据中获的模型的过程。在这个过程中使用的数据称为训练数据，里面的每个样本称为一个训练样本，也称训练示例或训练例。训练样本的集合就是训练集。

#### 模型(model)，学习器(learner)，假设(hypothesis)，真相(ground-truth)<br>
> 模型有时也称为学习器，可以看作一组参数的有序集合，能够把属性空间映射到输出空间上。每一个模型对应于一个假设，也即数据存在的某种规律。真相指的是真正存在的规律，学习就是为了接近真相。

如果我们希望通过机器学习来实现预测(prediction)，那么只有样本是不够的，要让机器明白怎样的样本会产生怎样的结果，还需要为每个样本设置标记，标记有可能是离散值（分类任务），也可能是连续值（回归任务）。带标记的数据集如下：

|编号|色泽|根蒂|敲声|标记|
|:-:|:-:|:-:|:-:|:-:|
|001|青绿|蜷缩|浊响|好瓜|
|002|乌黑|稍蜷|沉闷|坏瓜|
|003|浅白|硬挺|清脆|坏瓜|

#### 标记(label)，样例(example)，标记空间(label space)，输出空间<br>
> 标记指示的是对象的类别或者事件的结果，样本和标记组合起来就是样例。所有标记的集合称为标记空间，也称为输出空间。

#### 分类(classification)，回归(regression)，聚类(clustering)<br>
>  根据预测值的不同，可以把任务分为几种不同的类别。若预测的是离散值，比如“好瓜”，“坏瓜”，则该任务称为分类任务；若预测的是连续值，比如瓜的重量，则该任务称为回归任务；还有一种聚类任务，旨在基于某种度量将样本分为若干个簇(cluster)，使得同一簇内尽量相似，不同簇间尽量相异。聚类任务不需要对样本进行标记。

> 特别地，只涉及两种类别的分类任务称为二分类任务(binary classification)，通常称一个类为正类(positive class)，另一个类为反类或者负类(negative class)。涉及到多个类别的分类任务就称为多分类(multi-class classification)任务。

#### 测试(testing)，测试样本(testing sample)，测试示例(testing instance)<br>
> 训练完成后，使用模型预测新样本的标记这个过程称为测试。测试中使用到的样本称为测试样本，也称测试示例或测试例。

#### 监督学习(supervised learning)，无监督学习(unsupervised learning)<br>
> 根据训练样本是否标记可以把任务分为两大类，需要标记的是监督学习，不需要标记的是无监督学习。前者的代表是回归和分类，后者的代表是聚类。

#### 泛化(generalization)能力<br>
> 让机器进行学习的目标并不仅仅是为了让模型能在训练数据上有好的表现，我们更希望模型在新的样本上也能有良好的表现。模型适用于新样本的能力就称为泛化能力，泛化能力好的模型能够更好地适用于整个样本空间。

#### 独立同分布(independent and identically distributed)<br>
>  一般来说，训练数据只占训练空间很少的一部分，当我们希望这一小部分的采样能够很好地反映整个样本空间的情况，从而令学得的模型具有良好的泛化能力。通常假设样本空间中的所有样本都服从于一个未知的分布(distribution)，并且训练样本都是从该分布上独立采样所得，这就称为独立同分布。训练样本越多，越能反映该分布的特性，从而能学得泛化能力更强的模型。

## 假设空间

类似由样本构成的样本空间和由标记构成的标记空间，所有的假设共同构成了假设空间。学习的过程就可以看作是在假设空间中搜索最能**匹配(fit)**训练集的假设。

假设空间的规模有多大呢？举个例子，样本空间维度是3，也即每个样本由3个特征来表示。这三个属性可能的取值分别为3，2，2。那么假设空间的规模就是 `4 × 3 × 3 + 1 = 37`，为什么呢？因为除了可能的取值之外，每个属性还有一种选择就是使用通配符*号表示，即无论取何值都可以。所以一个有3种可能取值的属性在排列组合时有4种情形。最后的加一表示的是**$\varnothing$假设**，它对应的是一种无论属性取何值都不可能达到目的的状况。比方说，前面的假设都是假设怎样的瓜会是好瓜，而$\varnothing$假设则对应于好瓜根本不存在。

有时候会出现多个假设都能匹配训练集的情形，这些假设的集合就称为**版本空间(version space)**。版本空间是假设空间的子空间。


