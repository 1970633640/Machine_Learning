# 模型评估与选择

## 误差

在分类任务中，通常把错分的样本数占样本总数的比例称为**错误率（error rate）**。比如m个样本有a个预测错了，错误率就是`a/m`；与错误率相对的有**精度（accuracy）**，或者说正确率，数值上等于1-错误率。

更一般地，通常会把模型输出和真实值之间的差异称为**误差（error）**。在训练集上的误差称为**训练误差（training error）**或者**经验误差（empirical error）**。而在新样本上的误差则称为**泛化误差（generalization error）**。我们希望模型的泛化误差尽可能小，但现实是，我们无法知道新样本是怎样的，所以只能尽可能地利用训练数据来最小化经验误差。

但是否经验误差小，泛化误差就一定小呢？这不是一定的，如果模型相比训练数据来说过于复杂，那就很有可能把训练数据本身的一些特点当作整个样本空间的特点，从而使得在训练数据上有很小的经验误差，但一旦面对新样本就会有很大误差，这种情况叫做**过拟合（overfitting）**。相对的是**欠拟合（underfitting）**。

欠拟合很容易避免，只要适当地增加模型复杂度（比方说增加神经网络的层数）就好。但**过拟合是无法彻底避免的**，只能缓解（减少模型复杂度/增加训练数据），这也是机器学习发展中的一个关键阻碍。

在现实任务中，要处理一个问题，我们往往有多种算法可以选择，即使是同一个算法也需要进行参数的选择，这就是机器学习中的**模型选择（model selection）**问题。既然泛化误差无法使用，而经验误差又存在着过拟合问题，不适合作为标准，那么我们应该如何进行模型选择呢？针对这个问题，后面的三个小节会给出回答。
